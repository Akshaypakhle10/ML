{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sincnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshaypakhle10/ML/blob/master/Sincnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPadENsDwQic",
        "colab_type": "code",
        "outputId": "156f22da-568a-4e70-e360-eec18055f602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OpsItCNwbbx",
        "colab_type": "code",
        "outputId": "ba3e187c-4de9-412f-86c4-a98591b78e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd gdrive/My\\ Drive "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1X_XrkJwmHs",
        "colab_type": "code",
        "outputId": "16295d3a-73bf-434a-ba06-e9cfcca6b68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! bash export/download_voxcelb.sh vox1 test\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\n",
            "--2019-11-15 04:50:30--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1072793438 (1023M) [application/zip]\n",
            "Saving to: ‘vox1_test_wav.zip’\n",
            "\n",
            "vox1_test_wav.zip   100%[===================>]   1023M  21.9MB/s    in 48s     \n",
            "\n",
            "2019-11-15 04:51:18 (21.4 MB/s) - ‘vox1_test_wav.zip’ saved [1072793438/1072793438]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng5Ef51HaA-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "def flip(x, dim):\n",
        "    xsize = x.size()\n",
        "    dim = x.dim() + dim if dim < 0 else dim\n",
        "    x = x.contiguous()\n",
        "    x = x.view(-1, *xsize[dim:])\n",
        "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
        "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
        "    return x.view(xsize)\n",
        "\n",
        "\n",
        "def sinc(band,t_right):\n",
        "    y_right= torch.sin(2*math.pi*band*t_right)/(2*math.pi*band*t_right)\n",
        "    y_left= flip(y_right,0)\n",
        "\n",
        "    y=torch.cat([y_left,Variable(torch.ones(1)).cuda(),y_right])\n",
        "\n",
        "    return y\n",
        "    \n",
        "\n",
        "class SincConv_fast(nn.Module):\n",
        "    \"\"\"Sinc-based convolution\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : `int`\n",
        "        Number of input channels. Must be 1.\n",
        "    out_channels : `int`\n",
        "        Number of filters.\n",
        "    kernel_size : `int`\n",
        "        Filter length.\n",
        "    sample_rate : `int`, optional\n",
        "        Sample rate. Defaults to 16000.\n",
        "    Usage\n",
        "    -----\n",
        "    See `torch.nn.Conv1d`\n",
        "    Reference\n",
        "    ---------\n",
        "    Mirco Ravanelli, Yoshua Bengio,\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\n",
        "    https://arxiv.org/abs/1808.00158\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def to_mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
        "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
        "\n",
        "        super(SincConv_fast,self).__init__()\n",
        "\n",
        "        if in_channels != 1:\n",
        "            #msg = (f'SincConv only support one input channel '\n",
        "            #       f'(here, in_channels = {in_channels:d}).')\n",
        "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if kernel_size%2==0:\n",
        "            self.kernel_size=self.kernel_size+1\n",
        "            \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "\n",
        "        if bias:\n",
        "            raise ValueError('SincConv does not support bias.')\n",
        "        if groups > 1:\n",
        "            raise ValueError('SincConv does not support groups.')\n",
        "\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_low_hz = min_low_hz\n",
        "        self.min_band_hz = min_band_hz\n",
        "\n",
        "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        low_hz = 30\n",
        "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
        "\n",
        "        mel = np.linspace(self.to_mel(low_hz),\n",
        "                          self.to_mel(high_hz),\n",
        "                          self.out_channels + 1)\n",
        "        hz = self.to_hz(mel)\n",
        "        \n",
        "\n",
        "        # filter lower frequency (out_channels, 1)\n",
        "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "\n",
        "        # filter frequency band (out_channels, 1)\n",
        "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "\n",
        "        # Hamming window\n",
        "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
        "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
        "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
        "\n",
        "\n",
        "        # (kernel_size, 1)\n",
        "        n = (self.kernel_size - 1) / 2.0\n",
        "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
        "            Batch of waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
        "            Batch of sinc filters activations.\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "\n",
        "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
        "        \n",
        "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
        "        band=(high-low)[:,0]\n",
        "        \n",
        "        f_times_t_low = torch.matmul(low, self.n_)\n",
        "        f_times_t_high = torch.matmul(high, self.n_)\n",
        "\n",
        "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
        "        band_pass_center = 2*band.view(-1,1)\n",
        "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
        "        \n",
        "        \n",
        "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
        "\n",
        "        \n",
        "        band_pass = band_pass / (2*band[:,None])\n",
        "        \n",
        "\n",
        "        self.filters = (band_pass).view(\n",
        "            self.out_channels, 1, self.kernel_size)\n",
        "\n",
        "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
        "                        padding=self.padding, dilation=self.dilation,\n",
        "                         bias=None, groups=1) \n",
        "\n",
        "    \n",
        "\n",
        "def act_fun(act_type):\n",
        "\n",
        " if act_type==\"relu\":\n",
        "    return nn.ReLU()\n",
        "            \n",
        " if act_type==\"tanh\":\n",
        "    return nn.Tanh()\n",
        "            \n",
        " if act_type==\"sigmoid\":\n",
        "    return nn.Sigmoid()\n",
        "           \n",
        " if act_type==\"leaky_relu\":\n",
        "    return nn.LeakyReLU(0.2)\n",
        "            \n",
        " if act_type==\"elu\":\n",
        "    return nn.ELU()\n",
        "                     \n",
        " if act_type==\"softmax\":\n",
        "    return nn.LogSoftmax(dim=1)\n",
        "        \n",
        " if act_type==\"linear\":\n",
        "    return nn.LeakyReLU(1) # initializzed like this, but not used in forward!\n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3rE9_BS640b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_batches_rnd(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict,fact_amp):\n",
        "    \n",
        " # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
        " sig_batch=np.zeros([batch_size,wlen])\n",
        " lab_batch=np.zeros(batch_size)\n",
        "  \n",
        " snt_id_arr=np.random.randint(N_snt, size=batch_size)\n",
        " \n",
        " rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
        "\n",
        " for i in range(batch_size):\n",
        "     \n",
        "  [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
        "  # accesing to a random chunk\n",
        "  snt_len=signal.shape[0]\n",
        "  snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
        "  snt_end=snt_beg+wlen\n",
        "  \n",
        "  sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n",
        "  lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n",
        "  \n",
        " inp=torch.from_numpy(sig_batch).float().contiguous()  # Current Frame\n",
        " lab=torch.from_numpy(lab_batch).float().contiguous()\n",
        "  \n",
        " return inp,lab "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKAWhQBN-JaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadList(list_file):\n",
        " f=open(list_file,\"r\")\n",
        " lines=f.readlines()\n",
        " list_sig=[]\n",
        " for x in lines:\n",
        "    list_sig.append(x.rstrip())\n",
        " f.close()\n",
        " return list_sig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIHvb7qnfByM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(\"/content/gdrive/My Drive/export/corpora/VoxCeleb1/test\"):\n",
        "   for fname in files:\n",
        "       print(dirs,fname) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlNuxFHj0ySD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "path = \"/content/gdrive/My Drive/export/test/\"\n",
        "file_name = \"wav.scp\"\n",
        "fs =  16000\n",
        "cw_len=200\n",
        "cw_shift=10\n",
        "fact_amp = 0.2\n",
        "wlen=int(fs*cw_len/1000.00)\n",
        "wshift=int(fs*cw_shift/1000.00)\n",
        "batch_size=128\n",
        "N_epochs=1500\n",
        "N_batches=800\n",
        "N_eval_epoch=8\n",
        "seed=1234\n",
        "lab_dict = {}\n",
        "absolute_path = path+file_name\n",
        "f = open(absolute_path, \"r\")\n",
        "lines = f.readlines()\n",
        "obj = SincConv_fast( 80, 80, sample_rate=16000, in_channels=1,\n",
        "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50)\n",
        "# wav_lst_tr = file_name\n",
        "wav_lst_tr = []\n",
        "\n",
        "for each in lines:\n",
        "  id, file = each.split()\n",
        "  wav_lst_tr.append(file)\n",
        "  l = file.split(\"/\")\n",
        "  key = l[4]+ \"-\"+ l[5]\n",
        "  lab_dict[file] = l[6].strip(\".wav\")\n",
        "np.save(\"d.npy\", lab_dict)\n",
        "N_snt_tr = len(wav_lst_tr)\n",
        "# [inp,lab] = create_batches_rnd(128,'/content/gdrive/My Drive', wav_lst_tr, N_snt_tr, wlen, lab_dict,fact_amp)\n",
        "# x2 = inp.unsqueeze(1)\n",
        "# obj.forward(x2).data.numpy()\n",
        "\n",
        "for i in range(N_snt_tr//batch_size):\n",
        "  [inp,lab] = create_batches_rnd(128,'/content/gdrive/My Drive', wav_lst_tr, N_snt_tr, wlen, lab_dict,fact_amp)\n",
        "  x2 = inp.unsqueeze(1)\n",
        "  a = obj.forward(x2).data.numpy()\n",
        "  filename = \"d\"+str(i)+\".npy\"\n",
        "  np.save(filename, a)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}